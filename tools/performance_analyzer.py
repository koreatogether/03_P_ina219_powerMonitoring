#!/usr/bin/env python3
"""
INA219 Power Monitoring System - Performance Analyzer
ì „ë ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ë¶„ì„ ë„êµ¬

ë¶„ì„ í•­ëª©:
- ë°ì´í„° ìˆ˜ì§‘ ì„±ëŠ¥ ì¸¡ì •
- ëŒ€ì‹œë³´ë“œ ì‘ë‹µ ì‹œê°„ ë¶„ì„
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
- ì „ë ¥ ì¸¡ì • ì •í™•ë„ ê²€ì¦
- Arduino í†µì‹  ì„±ëŠ¥ ì¸¡ì •
"""

import os
import subprocess
import sys
import time
import statistics
from datetime import datetime
from pathlib import Path
import json
import psutil


class PowerMonitoringPerformanceAnalyzer:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.log_dir = self.project_root / "logs" / "performance"
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì„¤ì •
        self.test_iterations = 100
        self.warmup_iterations = 10
        
        # ê²°ê³¼ ì €ì¥
        self.results = {
            "timestamp": self.timestamp,
            "test_config": {
                "iterations": self.test_iterations,
                "warmup_iterations": self.warmup_iterations
            },
            "performance": {},
            "system_info": self.get_system_info()
        }
    
    def get_system_info(self):
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        return {
            "cpu_count": psutil.cpu_count(),
            "memory_total": psutil.virtual_memory().total,
            "python_version": sys.version,
            "platform": sys.platform
        }
    
    def run_command_with_timing(self, cmd, desc, cwd=None, iterations=1):
        """ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •"""
        print(f"â±ï¸  {desc} (ë°˜ë³µ: {iterations}íšŒ)")
        
        times = []
        outputs = []
        memory_usage = []
        
        for i in range(iterations):
            try:
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì‹œì‘
                process = psutil.Process()
                memory_before = process.memory_info().rss
                
                start_time = time.perf_counter()
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    cwd=cwd or self.project_root,
                    timeout=30,
                    encoding='utf-8',
                    errors='replace'
                )
                end_time = time.perf_counter()
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì¢…ë£Œ
                memory_after = process.memory_info().rss
                memory_diff = memory_after - memory_before
                
                execution_time = end_time - start_time
                times.append(execution_time)
                memory_usage.append(memory_diff)
                
                if result.returncode == 0:
                    outputs.append(result.stdout.strip())
                else:
                    print(f"    âŒ ì‹¤í–‰ ì‹¤íŒ¨ (ë°˜ë³µ {i+1}): {result.stderr}")
                    return None
                    
            except subprocess.TimeoutExpired:
                print(f"    â° íƒ€ì„ì•„ì›ƒ (ë°˜ë³µ {i+1})")
                return None
            except Exception as e:
                print(f"    âŒ ì˜¤ë¥˜ (ë°˜ë³µ {i+1}): {e}")
                return None
        
        if not times:
            return None
            
        return {
            "times": times,
            "outputs": outputs,
            "memory_usage": memory_usage,
            "avg_time": statistics.mean(times),
            "min_time": min(times),
            "max_time": max(times),
            "std_dev": statistics.stdev(times) if len(times) > 1 else 0,
            "avg_memory": statistics.mean(memory_usage) if memory_usage else 0,
            "success_rate": len(times) / iterations
        }
    
    def analyze_data_processing_performance(self):
        """ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ë¶„ì„"""
        print("\nğŸ“Š ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ë¶„ì„")
        print("-" * 30)
        
        data_processing_dir = self.project_root / "src" / "python" / "data_processing"
        if not data_processing_dir.exists():
            self.results["performance"]["data_processing"] = {
                "status": "skipped", 
                "reason": "No data processing module found"
            }
            return
        
        # ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì°¾ê¸°
        processing_files = list(data_processing_dir.glob("*.py"))
        if not processing_files:
            self.results["performance"]["data_processing"] = {
                "status": "skipped", 
                "reason": "No data processing files found"
            }
            return
        
        processing_results = {}
        
        for py_file in processing_files:
            if py_file.name.startswith("test_") or py_file.name == "__init__.py":
                continue
                
            print(f"  ğŸ“Š ë¶„ì„ ì¤‘: {py_file.name}")
            
            # ì›Œë°ì—…
            warmup_result = self.run_command_with_timing(
                f"python -m uv run python {py_file}",
                f"ì›Œë°ì—… {py_file.name}",
                iterations=self.warmup_iterations
            )
            
            if warmup_result is None:
                processing_results[py_file.name] = {"status": "failed", "reason": "Warmup failed"}
                continue
            
            # ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì •
            perf_result = self.run_command_with_timing(
                f"python -m uv run python {py_file}",
                f"ì„±ëŠ¥ ì¸¡ì • {py_file.name}",
                iterations=self.test_iterations
            )
            
            if perf_result is None:
                processing_results[py_file.name] = {"status": "failed", "reason": "Performance test failed"}
                continue
            
            processing_results[py_file.name] = {
                "performance": perf_result,
                "status": "success"
            }
            
            print(f"    âœ… í‰ê·  ì‹¤í–‰ì‹œê°„: {perf_result['avg_time']:.6f}ì´ˆ")
            print(f"    ğŸ’¾ í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©: {perf_result['avg_memory']/1024/1024:.2f}MB")
        
        self.results["performance"]["data_processing"] = processing_results
    
    def analyze_dashboard_performance(self):
        """ëŒ€ì‹œë³´ë“œ ì„±ëŠ¥ ë¶„ì„"""
        print("\nğŸ“ˆ ëŒ€ì‹œë³´ë“œ ì„±ëŠ¥ ë¶„ì„")
        print("-" * 30)
        
        dashboard_dir = self.project_root / "src" / "python" / "dashboard"
        if not dashboard_dir.exists():
            self.results["performance"]["dashboard"] = {
                "status": "skipped", 
                "reason": "No dashboard directory found"
            }
            return
        
        # ëŒ€ì‹œë³´ë“œ ì•± íŒŒì¼ ì°¾ê¸°
        app_files = list(dashboard_dir.glob("app.py")) + list(dashboard_dir.glob("main.py"))
        
        if not app_files:
            self.results["performance"]["dashboard"] = {
                "status": "skipped", 
                "reason": "No dashboard app file found"
            }
            return
        
        app_file = app_files[0]
        print(f"  ğŸ“Š ëŒ€ì‹œë³´ë“œ ë¡œë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: {app_file.name}")
        
        # ëŒ€ì‹œë³´ë“œ ì„í¬íŠ¸ ì„±ëŠ¥ ì¸¡ì •
        test_script = f"""
import time
import sys
sys.path.insert(0, '{dashboard_dir}')

start_time = time.perf_counter()
try:
    import {app_file.stem}
    end_time = time.perf_counter()
    print(f"Import time: {{end_time - start_time:.6f}} seconds")
except Exception as e:
    print(f"Import failed: {{e}}")
    sys.exit(1)
"""
        
        # ì›Œë°ì—…
        warmup_result = self.run_command_with_timing(
            f"python -m uv run python -c \"{test_script}\"",
            f"ëŒ€ì‹œë³´ë“œ ì„í¬íŠ¸ ì›Œë°ì—…",
            iterations=self.warmup_iterations
        )
        
        if warmup_result is None:
            self.results["performance"]["dashboard"] = {"status": "failed", "reason": "Warmup failed"}
            return
        
        # ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì •
        perf_result = self.run_command_with_timing(
            f"python -m uv run python -c \"{test_script}\"",
            f"ëŒ€ì‹œë³´ë“œ ì„í¬íŠ¸ ì„±ëŠ¥ ì¸¡ì •",
            iterations=self.test_iterations
        )
        
        if perf_result is None:
            self.results["performance"]["dashboard"] = {"status": "failed", "reason": "Performance test failed"}
            return
        
        self.results["performance"]["dashboard"] = {
            "performance": perf_result,
            "status": "success"
        }
        
        print(f"    âœ… í‰ê·  ì„í¬íŠ¸ ì‹œê°„: {perf_result['avg_time']:.6f}ì´ˆ")
        print(f"    ğŸ’¾ í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©: {perf_result['avg_memory']/1024/1024:.2f}MB")
    
    def analyze_serial_communication_performance(self):
        """ì‹œë¦¬ì–¼ í†µì‹  ì„±ëŠ¥ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)"""
        print("\nğŸ“¡ ì‹œë¦¬ì–¼ í†µì‹  ì„±ëŠ¥ ë¶„ì„")
        print("-" * 30)
        
        # ì‹œë¦¬ì–¼ í†µì‹  ì‹œë®¬ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        serial_test_script = """
import time
import random

# INA219 ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
def simulate_ina219_reading():
    voltage = round(random.uniform(3.0, 5.0), 3)
    current = round(random.uniform(0.0, 1000.0), 2)
    power = round(voltage * current / 1000, 3)
    return f"V:{voltage},I:{current},P:{power}"

# ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
start_time = time.perf_counter()
readings = []
for i in range(100):
    reading = simulate_ina219_reading()
    readings.append(reading)
    time.sleep(0.001)  # 1ms ì§€ì—° ì‹œë®¬ë ˆì´ì…˜

end_time = time.perf_counter()
print(f"Readings: {len(readings)}")
print(f"Time: {end_time - start_time:.6f} seconds")
print(f"Rate: {len(readings)/(end_time - start_time):.2f} readings/sec")
"""
        
        # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
        temp_script = self.project_root / "temp_serial_test.py"
        with open(temp_script, 'w', encoding='utf-8') as f:
            f.write(serial_test_script)
        
        try:
            print("  ğŸ“Š ì‹œë¦¬ì–¼ í†µì‹  ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸")
            
            # ì›Œë°ì—…
            warmup_result = self.run_command_with_timing(
                f"python -m uv run python {temp_script}",
                "ì‹œë¦¬ì–¼ í†µì‹  ì›Œë°ì—…",
                iterations=self.warmup_iterations
            )
            
            if warmup_result is None:
                self.results["performance"]["serial_communication"] = {"status": "failed", "reason": "Warmup failed"}
                return
            
            # ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì •
            perf_result = self.run_command_with_timing(
                f"python -m uv run python {temp_script}",
                "ì‹œë¦¬ì–¼ í†µì‹  ì„±ëŠ¥ ì¸¡ì •",
                iterations=self.test_iterations
            )
            
            if perf_result is None:
                self.results["performance"]["serial_communication"] = {"status": "failed", "reason": "Performance test failed"}
                return
            
            self.results["performance"]["serial_communication"] = {
                "performance": perf_result,
                "status": "success"
            }
            
            print(f"    âœ… í‰ê·  ì‹¤í–‰ì‹œê°„: {perf_result['avg_time']:.6f}ì´ˆ")
            print(f"    ğŸ’¾ í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©: {perf_result['avg_memory']/1024/1024:.2f}MB")
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if temp_script.exists():
                temp_script.unlink()
    
    def generate_performance_report(self):
        """ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nğŸ“Š ì„±ëŠ¥ ë¶„ì„ ìš”ì•½")
        print("-" * 30)
        
        summary = {
            "total_tests": 0,
            "successful_tests": 0,
            "average_times": {},
            "memory_usage": {}
        }
        
        # ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
        for component, results in self.results["performance"].items():
            if isinstance(results, dict) and results.get("status") == "success":
                if "performance" in results:
                    perf_data = results["performance"]
                    summary["total_tests"] += 1
                    summary["successful_tests"] += 1
                    summary["average_times"][component] = perf_data["avg_time"]
                    summary["memory_usage"][component] = perf_data.get("avg_memory", 0)
                else:
                    # ì—¬ëŸ¬ íŒŒì¼ ê²°ê³¼ì¸ ê²½ìš°
                    for file_name, file_result in results.items():
                        if isinstance(file_result, dict) and file_result.get("status") == "success":
                            perf_data = file_result["performance"]
                            summary["total_tests"] += 1
                            summary["successful_tests"] += 1
                            summary["average_times"][f"{component}_{file_name}"] = perf_data["avg_time"]
                            summary["memory_usage"][f"{component}_{file_name}"] = perf_data.get("avg_memory", 0)
            else:
                summary["total_tests"] += 1
        
        self.results["summary"] = summary
        
        # ê²°ê³¼ ì¶œë ¥
        if summary["average_times"]:
            print("\nğŸ† ì„±ëŠ¥ ìˆœìœ„ (ì‹¤í–‰ ì‹œê°„):")
            sorted_times = sorted(summary["average_times"].items(), key=lambda x: x[1])
            for i, (component, avg_time) in enumerate(sorted_times, 1):
                print(f"    {i}. {component}: {avg_time*1000:.3f}ms")
            
            print("\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
            for component, memory in summary["memory_usage"].items():
                if memory > 0:
                    print(f"    {component}: {memory/1024/1024:.2f}MB")
        else:
            print("  âŒ ë¶„ì„í•  ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def save_results(self):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        # JSON ê²°ê³¼ ì €ì¥
        json_file = self.log_dir / f"performance_analysis_{self.timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False, default=str)
        
        # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥
        text_file = self.log_dir / f"performance_report_{self.timestamp}.txt"
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write("INA219 Power Monitoring - Performance Analysis Report\n")
            f.write("=" * 60 + "\n")
            f.write(f"Timestamp: {self.timestamp}\n")
            f.write(f"Test Iterations: {self.test_iterations}\n")
            f.write(f"Warmup Iterations: {self.warmup_iterations}\n\n")
            
            # ì‹œìŠ¤í…œ ì •ë³´
            f.write("SYSTEM INFO:\n")
            f.write("-" * 20 + "\n")
            f.write(json.dumps(self.results["system_info"], indent=2, ensure_ascii=False))
            f.write("\n\n")
            
            # ì»´í¬ë„ŒíŠ¸ë³„ ê²°ê³¼
            for component, results in self.results["performance"].items():
                f.write(f"\n{component.upper()} RESULTS:\n")
                f.write("-" * 30 + "\n")
                f.write(json.dumps(results, indent=2, ensure_ascii=False, default=str))
                f.write("\n")
        
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ë¨:")
        print(f"  ğŸ“„ JSON: {json_file}")
        print(f"  ğŸ“„ ë¦¬í¬íŠ¸: {text_file}")
    
    def run_analysis(self):
        """ì „ì²´ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ INA219 Power Monitoring ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
        print("-" * 60)
        
        # ê° ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„
        self.analyze_data_processing_performance()
        self.analyze_dashboard_performance()
        self.analyze_serial_communication_performance()
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_performance_report()
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    analyzer = PowerMonitoringPerformanceAnalyzer(project_root)
    analyzer.run_analysis()


if __name__ == "__main__":
    main()